{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd04306536f51c054f28e72dcf7ec96a785d3a674150598f115abece5bce32b30bf",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clean parameter tunning"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from flp_dual_svm_ls import FlpDualLSSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows Ã— 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "# Read dataset\n",
    "\n",
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data separation from tarjet variable\n",
    "\n",
    "X = dataset.iloc[:, :dataset.shape[1] - 1]\n",
    "y = dataset.iloc[:, dataset.shape[1] - 1]"
   ]
  },
  {
   "source": [
    "## One-hot encoding"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     age  sex  trtbps  chol  fbs  thalachh  exng  oldpeak  slp  caa  thall  \\\n",
       "0     63    1     145   233    1       150     0      2.3    0    0      1   \n",
       "1     37    1     130   250    0       187     0      3.5    0    0      2   \n",
       "2     41    0     130   204    0       172     0      1.4    2    0      2   \n",
       "3     56    1     120   236    0       178     0      0.8    2    0      2   \n",
       "4     57    0     120   354    0       163     1      0.6    2    0      2   \n",
       "..   ...  ...     ...   ...  ...       ...   ...      ...  ...  ...    ...   \n",
       "298   57    0     140   241    0       123     1      0.2    1    0      3   \n",
       "299   45    1     110   264    0       132     0      1.2    1    0      3   \n",
       "300   68    1     144   193    1       141     0      3.4    1    2      3   \n",
       "301   57    1     130   131    0       115     1      1.2    1    1      3   \n",
       "302   57    0     130   236    0       174     0      0.0    1    1      2   \n",
       "\n",
       "     cp_0  cp_1  cp_2  cp_3  restecg_0  restecg_1  restecg_2  \n",
       "0       0     0     0     1          1          0          0  \n",
       "1       0     0     1     0          0          1          0  \n",
       "2       0     1     0     0          1          0          0  \n",
       "3       0     1     0     0          0          1          0  \n",
       "4       1     0     0     0          0          1          0  \n",
       "..    ...   ...   ...   ...        ...        ...        ...  \n",
       "298     1     0     0     0          0          1          0  \n",
       "299     0     0     0     1          0          1          0  \n",
       "300     1     0     0     0          0          1          0  \n",
       "301     1     0     0     0          0          1          0  \n",
       "302     0     1     0     0          1          0          0  \n",
       "\n",
       "[303 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>cp_0</th>\n      <th>cp_1</th>\n      <th>cp_2</th>\n      <th>cp_3</th>\n      <th>restecg_0</th>\n      <th>restecg_1</th>\n      <th>restecg_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows Ã— 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# One hot encoding to variables cp and test_ecg\n",
    "\n",
    "cp_dummies = pd.get_dummies(X.cp, prefix=\"cp\")\n",
    "X = pd.concat([X, cp_dummies], axis=1)\n",
    "X = X.drop([\"cp\"], axis=1)\n",
    "\n",
    "restecg_dummies = pd.get_dummies(X.restecg, prefix=\"restecg\")\n",
    "X = pd.concat([X, restecg_dummies], axis=1)\n",
    "X = X.drop([\"restecg\"], axis=1)\n",
    "\n",
    "X"
   ]
  },
  {
   "source": [
    "## Scaling"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.9521966 ,  0.68100522,  0.76395577, ...,  1.03015751,\n",
       "        -1.00330579, -0.11566299],\n",
       "       [-1.91531289,  0.68100522, -0.09273778, ..., -0.97072534,\n",
       "         0.9967051 , -0.11566299],\n",
       "       [-1.47415758, -1.46841752, -0.09273778, ...,  1.03015751,\n",
       "        -1.00330579, -0.11566299],\n",
       "       ...,\n",
       "       [ 1.50364073,  0.68100522,  0.70684287, ..., -0.97072534,\n",
       "         0.9967051 , -0.11566299],\n",
       "       [ 0.29046364,  0.68100522, -0.09273778, ..., -0.97072534,\n",
       "         0.9967051 , -0.11566299],\n",
       "       [ 0.29046364, -1.46841752, -0.09273778, ...,  1.03015751,\n",
       "        -1.00330579, -0.11566299]])"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Scaling data matrix\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "source": [
    "## Dimensionality reduction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Explained variance = 0.8083603217581655\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.25553604,  2.65571067,  1.55807171, ..., -1.42075039,\n",
       "        -0.53499617, -0.28448603],\n",
       "       [-1.07638438, -0.93312063,  1.47398236, ...,  1.10866222,\n",
       "        -1.7581646 ,  0.58030621],\n",
       "       [-1.91922965,  1.57762633, -1.60605915, ...,  0.7407146 ,\n",
       "        -0.87326308,  0.24630816],\n",
       "       ...,\n",
       "       [ 2.02291247, -1.50139988,  1.66371979, ...,  0.44751016,\n",
       "        -0.41793094,  0.45030942],\n",
       "       [ 1.48732588, -2.93400775, -0.26700887, ..., -0.24279765,\n",
       "         0.14563255, -0.43569588],\n",
       "       [-1.1246483 ,  1.92927186, -0.88011566, ...,  1.02149572,\n",
       "        -0.81785933, -0.64405812]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "# PCA application\n",
    "\n",
    "pca = decomposition.PCA(n_components=10)\n",
    "pca.fit(X)\n",
    "print(\"Explained variance =\", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "X = pca.transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "# y mapping to -1 and 1. Also, we extend de dimension of y\n",
    "\n",
    "y = pd.Series(y).map({0: -1, 1: 1}).values\n",
    "y = np.expand_dims(y, axis=1)\n",
    "y"
   ]
  },
  {
   "source": [
    "## Parameter selection"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lamb = 2\n",
      "deg = 1\n",
      "Train mean = 0.8412087912087911\n",
      "Test mean = 0.8010752688172044\n",
      "---\n",
      "lamb = 4\n",
      "deg = 1\n",
      "Train mean = 0.8415750915750916\n",
      "Test mean = 0.7978494623655913\n",
      "---\n",
      "lamb = 8\n",
      "deg = 1\n",
      "Train mean = 0.839746283128636\n",
      "Test mean = 0.8076344086021505\n",
      "---\n",
      "lamb = 16\n",
      "deg = 1\n",
      "Train mean = 0.8294925662572721\n",
      "Test mean = 0.7980645161290323\n",
      "---\n",
      "lamb = 2\n",
      "deg = 2\n",
      "Train mean = 0.6853089312648136\n",
      "Test mean = 0.6743010752688172\n",
      "---\n",
      "lamb = 4\n",
      "deg = 2\n",
      "Train mean = 0.6988849385908209\n",
      "Test mean = 0.6409677419354838\n",
      "---\n",
      "lamb = 8\n",
      "deg = 2\n",
      "Train mean = 0.7129363283775049\n",
      "Test mean = 0.6636559139784947\n",
      "---\n",
      "lamb = 16\n",
      "deg = 2\n",
      "Train mean = 0.6908707713854774\n",
      "Test mean = 0.6305376344086022\n",
      "---\n",
      "lamb = 2\n",
      "deg = 3\n",
      "Train mean = 0.8151651045033397\n",
      "Test mean = 0.7189247311827958\n",
      "---\n",
      "lamb = 4\n",
      "deg = 3\n",
      "Train mean = 0.7767197263520794\n",
      "Test mean = 0.7156989247311829\n",
      "---\n",
      "lamb = 8\n",
      "deg = 3\n",
      "Train mean = 0.7946186166774402\n",
      "Test mean = 0.7220430107526882\n",
      "---\n",
      "lamb = 16\n",
      "deg = 3\n",
      "Train mean = 0.7888022516698987\n",
      "Test mean = 0.6818279569892474\n",
      "---\n",
      "lamb = 2\n",
      "deg = 4\n",
      "Train mean = 0.8588194893341952\n",
      "Test mean = 0.7550537634408602\n",
      "---\n",
      "lamb = 4\n",
      "deg = 4\n",
      "Train mean = 0.8566203404438697\n",
      "Test mean = 0.7318279569892473\n",
      "---\n",
      "lamb = 8\n",
      "deg = 4\n",
      "Train mean = 0.856983947425124\n",
      "Test mean = 0.7616129032258064\n",
      "---\n",
      "lamb = 16\n",
      "deg = 4\n",
      "Train mean = 0.8613822452057747\n",
      "Test mean = 0.7583870967741935\n",
      "---\n",
      "lamb = 2\n",
      "deg = 5\n",
      "Train mean = 0.8606442577030814\n",
      "Test mean = 0.7747311827956989\n",
      "---\n",
      "lamb = 4\n",
      "deg = 5\n",
      "Train mean = 0.860279304029304\n",
      "Test mean = 0.7916129032258065\n",
      "---\n",
      "lamb = 8\n",
      "deg = 5\n",
      "Train mean = 0.8595399698340873\n",
      "Test mean = 0.7747311827956989\n",
      "---\n",
      "lamb = 16\n",
      "deg = 5\n",
      "Train mean = 0.8617539323421676\n",
      "Test mean = 0.8078494623655914\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Clean SVM training\n",
    "\n",
    "lambda_values = [2, 4, 8, 16]\n",
    "deg_values = [1, 2, 3, 4, 5]\n",
    " \n",
    "for deg in deg_values:\n",
    "    for lamb in lambda_values:\n",
    "        kfold = KFold(n_splits=10)\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in kfold.split(X):\n",
    "            X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx, :], y[test_idx, :]\n",
    "            svm = FlpDualLSSVM(lr=1e-2, lambd=lamb, kernel=\"poly\", degree=deg)\n",
    "            svm.fit(X_train, y_train)\n",
    "            train_scores.append(svm.score(X_train, y_train))\n",
    "            test_scores.append(svm.score(X_test, y_test))\n",
    "\n",
    "        print(\"lamb =\", lamb)\n",
    "        print(\"deg =\", deg)\n",
    "        print(\"Train mean =\", np.mean(train_scores))\n",
    "        print(\"Test mean =\", np.mean(test_scores))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean SVM training\n",
    "\n",
    "lambda_values = [2, 4, 8, 16]\n",
    "deg_values = [1, 2, 3, 4, 5]\n",
    " \n",
    "for deg in deg_values:\n",
    "    for lamb in lambda_values:\n",
    "        kfold = KFold(n_splits=10)\n",
    "        train_scores = []\n",
    "        test_scores = []\n",
    "        for train_idx, test_idx in kfold.split(X):\n",
    "            X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx, :], y[test_idx, :]\n",
    "            svm = FlpDualLSSVM(lr=1e-2, lambd=lamb, kernel=\"poly\", degree=deg)\n",
    "            svm.fit(X_train, y_train)\n",
    "            train_scores.append(svm.score(X_train, y_train))\n",
    "            test_scores.append(svm.score(X_test, y_test))\n",
    "\n",
    "        print(\"lamb =\", lamb)\n",
    "        print(\"deg =\", deg)\n",
    "        print(\"Train mean =\", np.mean(train_scores))\n",
    "        print(\"Test mean =\", np.mean(test_scores))\n",
    "        print(\"---\")"
   ]
  },
  {
   "source": [
    "\n",
    "kfold = KFold(n_splits=10)\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "for train_idx, test_idx in kfold.split(X):\n",
    "    X_train, X_test, y_train, y_test = X[train_idx, :], X[test_idx, :], y[train_idx, :], y[test_idx, :]\n",
    "    svm = FlpDualLSSVM(lr=1e-2, lambd=1, kernel=\"sigmoidal\", max_iter=80, gamma=1/X_train.shape[1], r=0)\n",
    "    svm.fit(X_train, y_train)\n",
    "    train_scores.append(svm.score(X_train, y_train))\n",
    "    test_scores.append(svm.score(X_test, y_test))\n",
    "\n",
    "print(\"Train mean =\", np.mean(train_scores))\n",
    "print(\"Test mean =\", np.mean(test_scores))\n",
    "print(\"---\")"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train mean = 0.7876562163326868\nTest mean = 0.7458064516129033\n---\n"
     ]
    }
   ]
  },
  {
   "source": [
    "### Selection test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "This evidence shows that a linear kernel with max_iter = 80, lr = 1e-2 and lambda = 8 is a good selection of parameters."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Dataset preparation for MPC"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Utilities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for one train-test experiment \n",
    "\n",
    "def split_dataset(X, y, train_percentage):\n",
    "    size_train = int(train_percentage * X.shape[0])\n",
    "\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    training_idx, test_idx = indices[:size_train], indices[size_train:]\n",
    "    X_train, X_test = X[training_idx,:], X[test_idx,:]\n",
    "    y_train, y_test = y[training_idx,:], y[test_idx,:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "def select_subset(X, y, size_train):\n",
    "    indices = np.random.permutation(size_train)\n",
    "    X_subset = X[indices, :]\n",
    "    y_subset = y[indices, :]\n",
    "    return X_subset, y_subset\n",
    "\n",
    "\n",
    "def save_dataset_csv(X, y, label):\n",
    "    df_save = pd.DataFrame(data=np.append(X, y, axis=1))\n",
    "    file_name = \"real_dataset_\" + label + \".csv\"\n",
    "    df_save.to_csv(file_name, index=False, columns=None)\n",
    "\n",
    "\n",
    "def save_dataset_parties(X, y, n_parties):\n",
    "    n_rows = X.shape[0]\n",
    "    n_cols = X.shape[1]\n",
    "    rows_per_party = n_rows // n_parties\n",
    "    last_party = 0 \n",
    "    if n_rows % n_parties != 0:\n",
    "        last_party = rows_per_party + (n_rows % n_parties)\n",
    "    else:\n",
    "        last_party = rows_per_party\n",
    "    \n",
    "    party_info_X = []\n",
    "    party_info_y = []\n",
    "    for i in range(n_parties - 1):\n",
    "        party_X_rows = []\n",
    "        party_y_rows = []\n",
    "        for j in range(rows_per_party):\n",
    "            party_X_rows.append(X[j + i * rows_per_party].tolist())\n",
    "            party_y_rows.append(y[j + i * rows_per_party][0])\n",
    "        party_info_X.append(party_X_rows)\n",
    "        party_info_y.append(party_y_rows)\n",
    "\n",
    "    # Last party\n",
    "    party_X_rows = []\n",
    "    party_y_rows = []\n",
    "    for j in range(last_party):\n",
    "        party_X_rows.append(X[j + rows_per_party * (n_parties - 1)].tolist())\n",
    "        party_y_rows.append(y[j + rows_per_party * (n_parties - 1)][0])\n",
    "    party_info_X.append(party_X_rows)\n",
    "    party_info_y.append(party_y_rows)\n",
    "\n",
    "    for i in range(n_parties - 1):\n",
    "        file_name = \"Input-P\" + str(i) + \"-0\"\n",
    "        file = open(file_name, \"w\")\n",
    "        file_str = \"\"\n",
    "        for j in range(rows_per_party):\n",
    "            for k in range(n_cols):\n",
    "                file_str += str(party_info_X[i][j][k]) + \" \"\n",
    "            file_str = file_str.strip()\n",
    "            file_str += \"\\n\"\n",
    "        \n",
    "        for j in range(rows_per_party):\n",
    "            file_str += str(party_info_y[i][j]) + \"\\n\"\n",
    "        \n",
    "        file.write(file_str)\n",
    "        file.close()\n",
    "    \n",
    "    # Last party write\n",
    "    file_name = \"Input-P\" + str(n_parties - 1) + \"-0\"\n",
    "    file = open(file_name, \"w\")\n",
    "    file_str = \"\"\n",
    "    for j in range(last_party):\n",
    "        for k in range(n_cols):\n",
    "            file_str += str(party_info_X[n_parties - 1][j][k]) + \" \"\n",
    "        file_str = file_str.strip()\n",
    "        file_str += \"\\n\"\n",
    "    \n",
    "    for j in range(last_party):\n",
    "        file_str += str(party_info_y[n_parties - 1][j]) + \"\\n\"\n",
    "    \n",
    "    file.write(file_str)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test_percentage = 0.3\n",
    "n_parties = 4\n",
    "\n",
    "# Data selection\n",
    "train_percentage_temp = 1 - test_percentage\n",
    "X_train, X_test, y_train, y_test = split_dataset(X, y, train_percentage_temp)\n",
    "\n",
    "# Data saving to .csv\n",
    "save_dataset_csv(X_train, y_train, \"train\")\n",
    "save_dataset_csv(X_test, y_test, \"test\")\n",
    "\n",
    "# Save data for MPC\n",
    "save_dataset_parties(X_train, y_train, n_parties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(212, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
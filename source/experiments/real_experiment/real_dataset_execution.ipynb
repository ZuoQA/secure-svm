{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn import decomposition\n",
    "\n",
    "from flp_dual_svm_ls import FlpDualLSSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>1</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>3</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>1</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>0</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>0</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>1</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 14 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Read dataset\n",
    "\n",
    "dataset = pd.read_csv(\"heart.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data separation from tarjet variable\n",
    "\n",
    "X = dataset.iloc[:, :dataset.shape[1] - 1]\n",
    "y = dataset.iloc[:, dataset.shape[1] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "     age  sex  trtbps  chol  fbs  thalachh  exng  oldpeak  slp  caa  thall  \\\n",
       "0     63    1     145   233    1       150     0      2.3    0    0      1   \n",
       "1     37    1     130   250    0       187     0      3.5    0    0      2   \n",
       "2     41    0     130   204    0       172     0      1.4    2    0      2   \n",
       "3     56    1     120   236    0       178     0      0.8    2    0      2   \n",
       "4     57    0     120   354    0       163     1      0.6    2    0      2   \n",
       "..   ...  ...     ...   ...  ...       ...   ...      ...  ...  ...    ...   \n",
       "298   57    0     140   241    0       123     1      0.2    1    0      3   \n",
       "299   45    1     110   264    0       132     0      1.2    1    0      3   \n",
       "300   68    1     144   193    1       141     0      3.4    1    2      3   \n",
       "301   57    1     130   131    0       115     1      1.2    1    1      3   \n",
       "302   57    0     130   236    0       174     0      0.0    1    1      2   \n",
       "\n",
       "     cp_0  cp_1  cp_2  cp_3  restecg_0  restecg_1  restecg_2  \n",
       "0       0     0     0     1          1          0          0  \n",
       "1       0     0     1     0          0          1          0  \n",
       "2       0     1     0     0          1          0          0  \n",
       "3       0     1     0     0          0          1          0  \n",
       "4       1     0     0     0          0          1          0  \n",
       "..    ...   ...   ...   ...        ...        ...        ...  \n",
       "298     1     0     0     0          0          1          0  \n",
       "299     0     0     0     1          0          1          0  \n",
       "300     1     0     0     0          0          1          0  \n",
       "301     1     0     0     0          0          1          0  \n",
       "302     0     1     0     0          1          0          0  \n",
       "\n",
       "[303 rows x 18 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>cp_0</th>\n      <th>cp_1</th>\n      <th>cp_2</th>\n      <th>cp_3</th>\n      <th>restecg_0</th>\n      <th>restecg_1</th>\n      <th>restecg_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>298</th>\n      <td>57</td>\n      <td>0</td>\n      <td>140</td>\n      <td>241</td>\n      <td>0</td>\n      <td>123</td>\n      <td>1</td>\n      <td>0.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>299</th>\n      <td>45</td>\n      <td>1</td>\n      <td>110</td>\n      <td>264</td>\n      <td>0</td>\n      <td>132</td>\n      <td>0</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>300</th>\n      <td>68</td>\n      <td>1</td>\n      <td>144</td>\n      <td>193</td>\n      <td>1</td>\n      <td>141</td>\n      <td>0</td>\n      <td>3.4</td>\n      <td>1</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>57</td>\n      <td>1</td>\n      <td>130</td>\n      <td>131</td>\n      <td>0</td>\n      <td>115</td>\n      <td>1</td>\n      <td>1.2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>302</th>\n      <td>57</td>\n      <td>0</td>\n      <td>130</td>\n      <td>236</td>\n      <td>0</td>\n      <td>174</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>303 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "# One hot encoding to variables cp and test_ecg\n",
    "\n",
    "cp_dummies = pd.get_dummies(X.cp, prefix=\"cp\")\n",
    "X = pd.concat([X, cp_dummies], axis=1)\n",
    "X = X.drop([\"cp\"], axis=1)\n",
    "\n",
    "restecg_dummies = pd.get_dummies(X.restecg, prefix=\"restecg\")\n",
    "X = pd.concat([X, restecg_dummies], axis=1)\n",
    "X = X.drop([\"restecg\"], axis=1)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 0.9521966 ,  0.68100522,  0.76395577, ...,  1.03015751,\n",
       "        -1.00330579, -0.11566299],\n",
       "       [-1.91531289,  0.68100522, -0.09273778, ..., -0.97072534,\n",
       "         0.9967051 , -0.11566299],\n",
       "       [-1.47415758, -1.46841752, -0.09273778, ...,  1.03015751,\n",
       "        -1.00330579, -0.11566299],\n",
       "       ...,\n",
       "       [ 1.50364073,  0.68100522,  0.70684287, ..., -0.97072534,\n",
       "         0.9967051 , -0.11566299],\n",
       "       [ 0.29046364,  0.68100522, -0.09273778, ..., -0.97072534,\n",
       "         0.9967051 , -0.11566299],\n",
       "       [ 0.29046364, -1.46841752, -0.09273778, ...,  1.03015751,\n",
       "        -1.00330579, -0.11566299]])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Scaling data matrix\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Explained variance = 0.8083603217581656\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 1.25553604,  2.65571067,  1.55807171, ..., -1.42075039,\n",
       "        -0.53499617, -0.28448603],\n",
       "       [-1.07638438, -0.93312063,  1.47398236, ...,  1.10866222,\n",
       "        -1.7581646 ,  0.58030621],\n",
       "       [-1.91922965,  1.57762633, -1.60605915, ...,  0.7407146 ,\n",
       "        -0.87326308,  0.24630816],\n",
       "       ...,\n",
       "       [ 2.02291247, -1.50139988,  1.66371979, ...,  0.44751016,\n",
       "        -0.41793094,  0.45030942],\n",
       "       [ 1.48732588, -2.93400775, -0.26700887, ..., -0.24279765,\n",
       "         0.14563255, -0.43569588],\n",
       "       [-1.1246483 ,  1.92927186, -0.88011566, ...,  1.02149572,\n",
       "        -0.81785933, -0.64405812]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# PCA application\n",
    "\n",
    "pca = decomposition.PCA(n_components=10)\n",
    "pca.fit(X)\n",
    "print(\"Explained variance =\", sum(pca.explained_variance_ratio_))\n",
    "\n",
    "X = pca.transform(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b350ee1e4069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# y mapping to -1 and 1. Also, we extend de dimension of y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 335\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSingleBlockManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 529\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# y mapping to -1 and 1. Also, we extend de dimension of y\n",
    "\n",
    "y = pd.Series(y).map({0: -1, 1: 1}).values\n",
    "y = np.expand_dims(y, axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "def split_dataset(X, y, train_percentage):\n",
    "    size_train = int(train_percentage * X.shape[0])\n",
    "\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    training_idx, test_idx = indices[:size_train], indices[size_train:]\n",
    "    X_train, X_test = X[training_idx,:], X[test_idx,:]\n",
    "    y_train, y_test = y[training_idx,:], y[test_idx,:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "train_percentage = 0.7\n",
    "X_train, X_test, y_train, y_test = split_dataset(X, y, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lamb = 1\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 1\n",
      "deg = 2\n",
      "Train score = 0.6273584905660378\n",
      "Test score = 0.5274725274725275\n",
      "---\n",
      "lamb = 1\n",
      "deg = 3\n",
      "Train score = 0.7264150943396226\n",
      "Test score = 0.6263736263736264\n",
      "---\n",
      "lamb = 1\n",
      "deg = 4\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.8131868131868132\n",
      "---\n",
      "lamb = 1\n",
      "deg = 5\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 1\n",
      "deg = 6\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 1\n",
      "deg = 7\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 2\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 2\n",
      "deg = 2\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.8131868131868132\n",
      "---\n",
      "lamb = 2\n",
      "deg = 3\n",
      "Train score = 0.7169811320754716\n",
      "Test score = 0.6593406593406593\n",
      "---\n",
      "lamb = 2\n",
      "deg = 4\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 2\n",
      "deg = 5\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 2\n",
      "deg = 6\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.8131868131868132\n",
      "---\n",
      "lamb = 2\n",
      "deg = 7\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 3\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 3\n",
      "deg = 2\n",
      "Train score = 0.8066037735849056\n",
      "Test score = 0.7252747252747253\n",
      "---\n",
      "lamb = 3\n",
      "deg = 3\n",
      "Train score = 0.8537735849056604\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 3\n",
      "deg = 4\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.8131868131868132\n",
      "---\n",
      "lamb = 3\n",
      "deg = 5\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 3\n",
      "deg = 6\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 3\n",
      "deg = 7\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 4\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 4\n",
      "deg = 2\n",
      "Train score = 0.6698113207547169\n",
      "Test score = 0.5934065934065934\n",
      "---\n",
      "lamb = 4\n",
      "deg = 3\n",
      "Train score = 0.8207547169811321\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 4\n",
      "deg = 4\n",
      "Train score = 0.8867924528301887\n",
      "Test score = 0.8351648351648352\n",
      "---\n",
      "lamb = 4\n",
      "deg = 5\n",
      "Train score = 0.8962264150943396\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 4\n",
      "deg = 6\n",
      "Train score = 0.9009433962264151\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 4\n",
      "deg = 7\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 5\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 5\n",
      "deg = 2\n",
      "Train score = 0.5943396226415094\n",
      "Test score = 0.5384615384615384\n",
      "---\n",
      "lamb = 5\n",
      "deg = 3\n",
      "Train score = 0.8443396226415094\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 5\n",
      "deg = 4\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 5\n",
      "deg = 5\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 5\n",
      "deg = 6\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 5\n",
      "deg = 7\n",
      "Train score = 0.8867924528301887\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 6\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 6\n",
      "deg = 2\n",
      "Train score = 0.8962264150943396\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 6\n",
      "deg = 3\n",
      "Train score = 0.8113207547169812\n",
      "Test score = 0.6813186813186813\n",
      "---\n",
      "lamb = 6\n",
      "deg = 4\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 6\n",
      "deg = 5\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 6\n",
      "deg = 6\n",
      "Train score = 0.8962264150943396\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 6\n",
      "deg = 7\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 7\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 7\n",
      "deg = 2\n",
      "Train score = 0.6226415094339622\n",
      "Test score = 0.6263736263736264\n",
      "---\n",
      "lamb = 7\n",
      "deg = 3\n",
      "Train score = 0.8160377358490566\n",
      "Test score = 0.7032967032967034\n",
      "---\n",
      "lamb = 7\n",
      "deg = 4\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 7\n",
      "deg = 5\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 7\n",
      "deg = 6\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 7\n",
      "deg = 7\n",
      "Train score = 0.8867924528301887\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 8\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 8\n",
      "deg = 2\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 8\n",
      "deg = 3\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7362637362637363\n",
      "---\n",
      "lamb = 8\n",
      "deg = 4\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 8\n",
      "deg = 5\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 8\n",
      "deg = 6\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 8\n",
      "deg = 7\n",
      "Train score = 0.8867924528301887\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 9\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 9\n",
      "deg = 2\n",
      "Train score = 0.6650943396226415\n",
      "Test score = 0.5714285714285714\n",
      "---\n",
      "lamb = 9\n",
      "deg = 3\n",
      "Train score = 0.75\n",
      "Test score = 0.7362637362637363\n",
      "---\n",
      "lamb = 9\n",
      "deg = 4\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 9\n",
      "deg = 5\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 9\n",
      "deg = 6\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 9\n",
      "deg = 7\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 10\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 10\n",
      "deg = 2\n",
      "Train score = 0.6509433962264151\n",
      "Test score = 0.5714285714285714\n",
      "---\n",
      "lamb = 10\n",
      "deg = 3\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 10\n",
      "deg = 4\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 10\n",
      "deg = 5\n",
      "Train score = 0.8490566037735849\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 10\n",
      "deg = 6\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.8131868131868132\n",
      "---\n",
      "lamb = 10\n",
      "deg = 7\n",
      "Train score = 0.8867924528301887\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 11\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 11\n",
      "deg = 2\n",
      "Train score = 0.6226415094339622\n",
      "Test score = 0.5604395604395604\n",
      "---\n",
      "lamb = 11\n",
      "deg = 3\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 11\n",
      "deg = 4\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 11\n",
      "deg = 5\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7362637362637363\n",
      "---\n",
      "lamb = 11\n",
      "deg = 6\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 11\n",
      "deg = 7\n",
      "Train score = 0.9009433962264151\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 12\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 12\n",
      "deg = 2\n",
      "Train score = 0.8490566037735849\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 12\n",
      "deg = 3\n",
      "Train score = 0.7452830188679245\n",
      "Test score = 0.6703296703296703\n",
      "---\n",
      "lamb = 12\n",
      "deg = 4\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 12\n",
      "deg = 5\n",
      "Train score = 0.8537735849056604\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 12\n",
      "deg = 6\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 12\n",
      "deg = 7\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 13\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 13\n",
      "deg = 2\n",
      "Train score = 0.6556603773584906\n",
      "Test score = 0.5934065934065934\n",
      "---\n",
      "lamb = 13\n",
      "deg = 3\n",
      "Train score = 0.8113207547169812\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 13\n",
      "deg = 4\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 13\n",
      "deg = 5\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 13\n",
      "deg = 6\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 13\n",
      "deg = 7\n",
      "Train score = 0.8962264150943396\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 14\n",
      "deg = 1\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 14\n",
      "deg = 2\n",
      "Train score = 0.6415094339622641\n",
      "Test score = 0.5604395604395604\n",
      "---\n",
      "lamb = 14\n",
      "deg = 3\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 14\n",
      "deg = 4\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 14\n",
      "deg = 5\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 14\n",
      "deg = 6\n",
      "Train score = 0.8443396226415094\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 14\n",
      "deg = 7\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 15\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 15\n",
      "deg = 2\n",
      "Train score = 0.6132075471698113\n",
      "Test score = 0.5714285714285714\n",
      "---\n",
      "lamb = 15\n",
      "deg = 3\n",
      "Train score = 0.6886792452830188\n",
      "Test score = 0.5934065934065934\n",
      "---\n",
      "lamb = 15\n",
      "deg = 4\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.8021978021978022\n",
      "---\n",
      "lamb = 15\n",
      "deg = 5\n",
      "Train score = 0.9009433962264151\n",
      "Test score = 0.8021978021978022\n",
      "---\n",
      "lamb = 15\n",
      "deg = 6\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 15\n",
      "deg = 7\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 16\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 16\n",
      "deg = 2\n",
      "Train score = 0.6084905660377359\n",
      "Test score = 0.5824175824175825\n",
      "---\n",
      "lamb = 16\n",
      "deg = 3\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 16\n",
      "deg = 4\n",
      "Train score = 0.8679245283018868\n",
      "Test score = 0.7362637362637363\n",
      "---\n",
      "lamb = 16\n",
      "deg = 5\n",
      "Train score = 0.8962264150943396\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 16\n",
      "deg = 6\n",
      "Train score = 0.8962264150943396\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 16\n",
      "deg = 7\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 17\n",
      "deg = 1\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 17\n",
      "deg = 2\n",
      "Train score = 0.6839622641509434\n",
      "Test score = 0.6373626373626373\n",
      "---\n",
      "lamb = 17\n",
      "deg = 3\n",
      "Train score = 0.8490566037735849\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 17\n",
      "deg = 4\n",
      "Train score = 0.9056603773584906\n",
      "Test score = 0.8021978021978022\n",
      "---\n",
      "lamb = 17\n",
      "deg = 5\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 17\n",
      "deg = 6\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 17\n",
      "deg = 7\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 18\n",
      "deg = 1\n",
      "Train score = 0.8632075471698113\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 18\n",
      "deg = 2\n",
      "Train score = 0.6415094339622641\n",
      "Test score = 0.6263736263736264\n",
      "---\n",
      "lamb = 18\n",
      "deg = 3\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 18\n",
      "deg = 4\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 18\n",
      "deg = 5\n",
      "Train score = 0.8915094339622641\n",
      "Test score = 0.7802197802197802\n",
      "---\n",
      "lamb = 18\n",
      "deg = 6\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7582417582417582\n",
      "---\n",
      "lamb = 18\n",
      "deg = 7\n",
      "Train score = 0.8820754716981132\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 19\n",
      "deg = 1\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7692307692307693\n",
      "---\n",
      "lamb = 19\n",
      "deg = 2\n",
      "Train score = 0.6509433962264151\n",
      "Test score = 0.5824175824175825\n",
      "---\n",
      "lamb = 19\n",
      "deg = 3\n",
      "Train score = 0.8584905660377359\n",
      "Test score = 0.7912087912087912\n",
      "---\n",
      "lamb = 19\n",
      "deg = 4\n",
      "Train score = 0.8867924528301887\n",
      "Test score = 0.8021978021978022\n",
      "---\n",
      "lamb = 19\n",
      "deg = 5\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7252747252747253\n",
      "---\n",
      "lamb = 19\n",
      "deg = 6\n",
      "Train score = 0.8773584905660378\n",
      "Test score = 0.7472527472527473\n",
      "---\n",
      "lamb = 19\n",
      "deg = 7\n",
      "Train score = 0.8726415094339622\n",
      "Test score = 0.7692307692307693\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Clean SVM training\n",
    "\n",
    "for lamb in range(1, 20):\n",
    "    for deg in range(1, 8):\n",
    "        svm = FlpDualLSSVM(lr=1e-2, lambd=lamb, kernel=\"poly\", degree=deg)\n",
    "        svm.fit(X_train, y_train)\n",
    "\n",
    "        print(\"lamb =\", lamb)\n",
    "        print(\"deg =\", deg)\n",
    "        print(\"Train score =\", svm.score(X_train, y_train))\n",
    "        print(\"Test score =\", svm.score(X_test, y_test))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train score = 0.8490566037735849\nTest score = 0.7912087912087912\n"
     ]
    }
   ],
   "source": [
    "svm = FlpDualLSSVM(lr=1e-2, lambd=3, kernel=\"linear\")\n",
    "svm.fit(X_train, y_train)\n",
    "print(\"Train score =\", svm.score(X_train, y_train))\n",
    "print(\"Test score =\", svm.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}